{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3778b54a",
   "metadata": {},
   "source": [
    "<!-- ABSTRACT -->\n",
    "Put this notebook in root directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b609abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from tensordict import TensorDict\n",
    "\n",
    "from benchmarl.experiment import Experiment\n",
    "from env.energy_trading import EnergyTradingEnv\n",
    "from env.contract_proposal import ContractProposalEnv\n",
    "\n",
    "from thesis_results.utils import set_plot_style, aid_mapping, color_mapping\n",
    "set_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta Madness\n",
    "data = json.load(open(\"data/ausgrid/group_4.json\", \"r\"))\n",
    "agents = list(aid_mapping.keys())\n",
    "test_days = data['meta']['test_days']\n",
    "is_weekend_list = data['meta']['is_weekend']\n",
    "is_summer_list = data['meta']['is_summer']\n",
    "is_winter_list = data['meta']['is_winter']\n",
    "\n",
    "seeds = range(8)\n",
    "stage_2_seeds = range(8, 16)\n",
    "\n",
    "# Get best model, prefer later epochs\n",
    "def last_argmax(lst):\n",
    "    arr = np.array(lst)\n",
    "    return np.where(arr == arr.max())[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a189026",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e811953",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = ['DA', 'Pool', 'Mix', 'Grid', 'Mix_2',\n",
    "         'MAPPO', 'MADDPG'] # 'MAPPO' and 'MADDPG' are just DA, Hack for Appendix B\n",
    "learning_data = {algo: dict() for algo in algos}\n",
    "\n",
    "# Parse data\n",
    "for algo in ['DA', 'Pool', 'Mix', 'Grid', 'Mix_2']:\n",
    "\n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "\n",
    "    for seed in seeds:\n",
    "\n",
    "        # Training\n",
    "        filepath = f'results/{algo.lower().split(\"_\")[0]}/{'stage_1/' if algo=='Mix' else 'stage_2/' if algo=='Mix_2' else ''}{'ippo' if algo=='Grid' else 'mappo'}/seed_{seed+8 if algo=='Mix_2' else seed}/seed_{seed+8 if algo=='Mix_2' else seed}/scalars/collection_agents_reward_episode_reward_mean.csv'\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = [float(row[1]) for row in reader]\n",
    "            train_data.append(data)\n",
    "\n",
    "        # Evaluation\n",
    "        filepath = f'results/{algo.lower().split(\"_\")[0]}/{'stage_1/' if algo=='Mix' else 'stage_2/' if algo=='Mix_2' else ''}{'ippo' if algo=='Grid' else 'mappo'}/seed_{seed+8 if algo=='Mix_2' else seed}/seed_{seed+8 if algo=='Mix_2' else seed}/scalars/eval_agents_reward_episode_reward_mean.csv'\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = [float(row[1]) for row in reader]\n",
    "            eval_data.append(data)\n",
    "\n",
    "    learning_data[algo]['train'] = np.array(train_data)\n",
    "    learning_data[algo]['eval'] = np.array(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(learning_data, algos, split=\"train\", plot_var=True, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot learning curves (train or eval) for multiple algorithms.\n",
    "    Rewards are converted to costs by multiplying with -8.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_data : dict\n",
    "        Structure:\n",
    "        learning_data[algo]['train'] -> (n_seeds, n_steps)\n",
    "        learning_data[algo]['eval']  -> (n_seeds, n_steps)\n",
    "    algos : list\n",
    "        Algorithms to plot (keys in learning_data).\n",
    "    split : str\n",
    "        Which split to plot: 'train' or 'eval'.\n",
    "    save_path : str or None\n",
    "        Path to save figure if given.\n",
    "    \"\"\"\n",
    "\n",
    "    assert split in [\"train\", \"eval\"], \"split must be 'train' or 'eval'\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    steps = np.arange(learning_data[algos[0]][split].shape[1])\n",
    "\n",
    "    for algo in algos:\n",
    "        values = learning_data[algo][split] * -8  # reward → cost\n",
    "        mean_vals = values.mean(axis=0)\n",
    "        std_vals = values.std(axis=0)\n",
    "\n",
    "        plt.plot(\n",
    "            steps, mean_vals, \n",
    "            label=f\"{algo}\"\n",
    "        )\n",
    "\n",
    "        if plot_var:\n",
    "            plt.fill_between(\n",
    "                steps,\n",
    "                mean_vals - std_vals,\n",
    "                mean_vals + std_vals,\n",
    "                alpha=0.2\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Collection Steps\")\n",
    "    plt.ylabel(\"Episodic Community Cost ($)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5.1 and 5.2\n",
    "plot_learning_curves(learning_data,\n",
    "                     ['DA', 'Pool', 'Mix', 'Grid'],\n",
    "                     split=\"eval\",\n",
    "                     save_path=\"thesis_results/plots/05_results/learning_curve_eval.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack for MADDPG, Appendix B\n",
    "filepath = f'results/da/maddpg/seed_0/seed_0/scalars/collection_agents_reward_episode_reward_mean.csv'\n",
    "with open(filepath, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    train_data = [float(row[1]) for row in reader]\n",
    "\n",
    "filepath = f'results/da/maddpg/seed_0/seed_0/scalars/eval_agents_reward_episode_reward_mean.csv'\n",
    "with open(filepath, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    eval_data = [float(row[1]) for row in reader]\n",
    "\n",
    "learning_data['MAPPO']['train'] = learning_data['DA']['train']\n",
    "learning_data['MAPPO']['eval'] = learning_data['DA']['eval']\n",
    "learning_data['MADDPG']['train'] = np.array([train_data for _ in range(8)])\n",
    "learning_data['MADDPG']['eval'] = np.array([eval_data for _ in range(8)])\n",
    "\n",
    "plot_learning_curves(learning_data,\n",
    "                     ['MAPPO', 'MADDPG'],\n",
    "                     split=\"eval\",\n",
    "                     plot_var=False,\n",
    "                     save_path=\"thesis_results/plots/appendix_B/maddpg_eval_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot for Second Stage Training (5.3)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "steps = np.arange(16)\n",
    "\n",
    "for split in [\"train\", \"eval\"]:\n",
    "    values = learning_data[\"Mix_2\"][split] * -8  # reward → cost\n",
    "    mean_vals = values.mean(axis=0)\n",
    "    std_vals = values.std(axis=0)\n",
    "\n",
    "    plt.plot(\n",
    "        steps, mean_vals, \n",
    "        label=f\"{\"Training\" if split==\"train\" else \"Evaluation\"}\"\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        steps,\n",
    "        mean_vals - std_vals,\n",
    "        mean_vals + std_vals,\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Collection Steps\")\n",
    "plt.ylabel(\"Episodic Community Cost ($)\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3eec7",
   "metadata": {},
   "source": [
    "### Get Optimal Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashmap for optimal contracts\n",
    "optimal_contracts = dict()\n",
    "\n",
    "# Grid Config, Time of Use\n",
    "ToU = [0.15, 0.22, 0.44]\n",
    "\n",
    "FiT = 0.04  # Grid Config, Feed-in Tariff\n",
    "\n",
    "# Timestep (hours) to ToU period, AER 2019\n",
    "summer_timemap = [0, 0, 0, 0, 0, 0, 0, # 12 AM - 7 AM\n",
    "                        1, 1, 1, 1, 1, 1, 1, # 7 AM - 2 PM\n",
    "                        2, 2, 2, 2, 2, 2, # 2 PM - 8 PM\n",
    "                        1, 1, # 8 PM - 10 PM\n",
    "                        0, 0] # 10 PM - 12 AM\n",
    "\n",
    "winter_timemap = [0, 0, 0, 0, 0, 0, 0, # 12 AM - 7 AM\n",
    "                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, # 7 AM - 5 PM\n",
    "                        2, 2, 2, 2, # 5 PM - 9 PM\n",
    "                        1, # 9 PM - 10 PM\n",
    "                        0, 0] # 10 PM - 12 AM\n",
    "\n",
    "weekend_timemap = [0, 0, 0, 0, 0, 0, 0, # 12 AM - 7 AM\n",
    "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, # 7 AM - 10 PM\n",
    "                   0, 0] # 10 PM - 12 AM\n",
    "\n",
    "def timestep_to_ToU_period(timestep, is_weekend, is_summer, is_winter):\n",
    "\n",
    "    # Ultra realistic, AER 2019\n",
    "    if is_weekend or (not (is_summer or is_winter)):\n",
    "        return weekend_timemap[timestep % 24]\n",
    "    elif is_summer:\n",
    "        return summer_timemap[timestep % 24]\n",
    "    else:\n",
    "        return winter_timemap[timestep % 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in tqdm(stage_2_seeds):\n",
    "\n",
    "    # Evaluation\n",
    "    filepath = f\"results/mix/stage_2/mappo/seed_{seed}/seed_{seed}/scalars/eval_agents_reward_episode_reward_mean.csv\"\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = [float(row[1]) for row in reader]\n",
    "\n",
    "    best_idx = last_argmax(data)\n",
    "    best_exp = Experiment.reload_from_file(f\"results/mix/stage_2/mappo/seed_{seed}/checkpoints/checkpoint_{(best_idx+1)*4096}.pt\")\n",
    "    config = best_exp.task.config\n",
    "    proposal_env = ContractProposalEnv(config, render_mode=None)\n",
    "    \n",
    "    for is_weekend in [True, False]:\n",
    "        for is_summer in [True, False]:\n",
    "            for is_winter in [True, False]:\n",
    "            \n",
    "                if is_summer and is_winter:\n",
    "                    continue\n",
    "\n",
    "                optimal_contract = [dict() for _ in range(24)]\n",
    "\n",
    "                for timestep in range(24):\n",
    "\n",
    "                    t = timestep/24\n",
    "\n",
    "                    obs = [ToU[timestep_to_ToU_period(timestep, is_weekend, is_summer, is_winter)],\n",
    "                        FiT,\n",
    "                        np.sin(2 * np.pi * t),\n",
    "                        np.cos(2 * np.pi * t),\n",
    "                        int(is_weekend),\n",
    "                        int(is_summer),\n",
    "                        int(is_winter)]\n",
    "\n",
    "                    stacked_obs = Tensor(np.array([obs for aid in best_exp.group_map['agents']], dtype=np.float32))\n",
    "                    obs_tdict = TensorDict(agents=TensorDict(observation=stacked_obs)).to(best_exp.policy.device)\n",
    "\n",
    "                    actions = best_exp.policy.forward(obs_tdict)['agents']['action'].detach().cpu().numpy()\n",
    "                    action_dict = {aid: actions[i] for i, aid in enumerate(best_exp.group_map['agents'])}\n",
    "\n",
    "                    for aid in best_exp.group_map['agents']:\n",
    "                        optimal_contract[timestep][aid] = action_dict[aid][0]\n",
    "\n",
    "                optimal_contracts[(seed, is_weekend, is_summer, is_winter)] = optimal_contract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f047b37",
   "metadata": {},
   "source": [
    "### Compute Results on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the metrics we want to log\n",
    "logging_metrics = ['qnt', 'da_grid_qnt', 'da_p2p_qnt', 'mix_pool_qnt', 'es_charge',\n",
    "                   'reward', 'soc_action', 'price_action',\n",
    "                   'avg_clearing_price', 'da_unmatched']\n",
    "\n",
    "# Apply base policy to trade, assuming single group\n",
    "def trade_forward(base_exp, obs):\n",
    "\n",
    "    stacked_obs = Tensor(np.array([obs[aid] for aid in base_exp.group_map['agents']], dtype=np.float32))\n",
    "    obs_tdict = TensorDict(agents=TensorDict(observation=stacked_obs)).to(base_exp.policy.device)\n",
    "\n",
    "    actions = base_exp.policy.forward(obs_tdict)['agents']['action'].detach().cpu().numpy()\n",
    "    action_dict = {aid: actions[i] for i, aid in enumerate(base_exp.group_map['agents'])}\n",
    "\n",
    "    # Clear memory\n",
    "    del obs_tdict\n",
    "    del actions\n",
    "    \n",
    "    return action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef06978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(base_exp, trading_env, seed, algo, use_contracts=False):\n",
    "\n",
    "    total_info = {aid: {metric: [[] for _ in range(len(test_days))] for metric in logging_metrics} for aid in agents}\n",
    "\n",
    "    for i, day in enumerate(sorted(test_days)):\n",
    "        \n",
    "        if not use_contracts:\n",
    "            obs, infos = trading_env.reset(options={\"day\": day})\n",
    "        else:\n",
    "            obs, infos = trading_env.reset(options={\"day\": day, \"contracts\": optimal_contracts[(seed+8,\n",
    "                                                                                                is_weekend_list[day],\n",
    "                                                                                                is_summer_list[day],\n",
    "                                                                                                is_winter_list[day])]})\n",
    "\n",
    "        # Step environment for an episode\n",
    "        for t in range(trading_env.eps_len):\n",
    "\n",
    "            # Environment actor\n",
    "            actions = trade_forward(base_exp,obs)\n",
    "\n",
    "            obs, rewards, terminations, truncations, infos = trading_env.step(actions)\n",
    "\n",
    "            for aid in agents:\n",
    "                total_info[aid][\"qnt\"][i].append(infos[aid][\"qnt\"])\n",
    "                total_info[aid][\"da_grid_qnt\"][i].append(infos[aid][\"da_grid_qnt\"])\n",
    "                total_info[aid][\"da_p2p_qnt\"][i].append(infos[aid][\"da_p2p_qnt\"])\n",
    "                total_info[aid][\"mix_pool_qnt\"][i].append(infos[aid][\"mix_pool_qnt\"])\n",
    "                total_info[aid][\"reward\"][i].append(rewards[aid])\n",
    "                total_info[aid][\"es_charge\"][i].append(infos[aid][\"es_charge\"])\n",
    "                total_info[aid][\"soc_action\"][i].append(actions[aid][0 if algo in ['pool', 'grid'] else 1])\n",
    "                total_info[aid][\"price_action\"][i].append(actions[aid][0] if algo in ['da', 'mix'] else None)\n",
    "                total_info[aid][\"avg_clearing_price\"][i].append(infos[aid][\"avg_clearing_price\"])\n",
    "                total_info[aid][\"da_unmatched\"][i].append(infos[aid][\"da_unmatched\"])\n",
    "\n",
    "    return total_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ca0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results(algo):\n",
    "\n",
    "    # Dummy for task config\n",
    "    base_exp_path = f\"results/{algo}/{'stage_1/' if algo=='mix' else ''}{'ippo' if algo=='grid' else 'mappo'}/seed_0/checkpoints/checkpoint_524288.pt\"\n",
    "    base_exp = Experiment.reload_from_file(base_exp_path)\n",
    "    config = base_exp.task.config\n",
    "\n",
    "    # Single env for all evaluations\n",
    "    trading_env = EnergyTradingEnv(config, render_mode=None)\n",
    "    trading_env.reset(seed=2025)\n",
    "\n",
    "    grand_info = {aid: {metric: list() for metric in logging_metrics} for aid in agents}\n",
    "\n",
    "    for seed in tqdm(seeds):\n",
    "\n",
    "        # Evaluation\n",
    "        filepath = f'results/{algo}/{'stage_1/' if algo=='mix' else ''}{'ippo' if algo=='grid' else 'mappo'}/seed_{seed}/seed_{seed}/scalars/eval_agents_reward_episode_reward_mean.csv'\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = [float(row[1]) for row in reader]\n",
    "\n",
    "        best_idx = last_argmax(data)\n",
    "        best_exp = Experiment.reload_from_file(f\"results/{algo}/{'stage_1/' if algo=='mix' else ''}{'ippo' if algo=='grid' else 'mappo'}/seed_{seed}/checkpoints/checkpoint_{(best_idx+1)*8192}.pt\")\n",
    "\n",
    "        info = get_results(best_exp, trading_env, seed, algo, use_contracts=True if algo == 'mix' else False)\n",
    "        \n",
    "        for aid in agents:\n",
    "            for metric in logging_metrics:\n",
    "                grand_info[aid][metric].append(info[aid][metric])\n",
    "\n",
    "    return grand_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#### Get all results ####\n",
    "#########################\n",
    "\n",
    "base_info = aggregate_results('grid') # Grid Only Baseline\n",
    "da_info = aggregate_results('da')\n",
    "pool_info = aggregate_results('pool')\n",
    "mix_info = aggregate_results('mix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638409f",
   "metadata": {},
   "source": [
    "### Chapter 5 Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d460aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5.1 - Daily Rewards\n",
    "for aid in sorted(agents):\n",
    "\n",
    "    base_reward = np.array(base_info[aid][\"reward\"]).sum(axis=-1)\n",
    "    da_reward = np.array(da_info[aid][\"reward\"]).sum(axis=-1)\n",
    "    pool_reward = np.array(pool_info[aid][\"reward\"]).sum(axis=-1)\n",
    "    mix_reward = np.array(mix_info[aid][\"reward\"]).sum(axis=-1)\n",
    "\n",
    "    print(f\"{aid} & ${base_reward.mean():.2f} \\\\pm {base_reward.std():.2f}$ [{np.percentile(base_reward, 5):.2f}] & ${da_reward.mean():.2f} \\\\pm {da_reward.std():.2f}$ [{np.percentile(da_reward, 5):.2f}] & ${pool_reward.mean():.2f} \\\\pm {pool_reward.std():.2f}$ [{np.percentile(pool_reward, 5):.2f}] & ${mix_reward.mean():.2f} \\\\pm {mix_reward.std():.2f}$ [{np.percentile(mix_reward, 5):.2f}] \\\\\\\\\")\n",
    "\n",
    "ec_base_reward = sum([np.array(base_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1)\n",
    "ec_da_reward = sum([np.array(da_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1)\n",
    "ec_pool_reward = sum([np.array(pool_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1)\n",
    "ec_mix_reward = sum([np.array(mix_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1)\n",
    "\n",
    "print(f\"Community & ${ec_base_reward.mean():.2f} \\\\pm {ec_base_reward.std():.2f}$ [{np.percentile(ec_base_reward, 5):.2f}] & ${ec_da_reward.mean():.2f} \\\\pm {ec_da_reward.std():.2f}$ [{np.percentile(ec_da_reward, 5):.2f}] & ${ec_pool_reward.mean():.2f} \\\\pm {ec_pool_reward.std():.2f}$ [{np.percentile(ec_pool_reward, 5):.2f}] & ${ec_mix_reward.mean():.2f} \\\\pm {ec_mix_reward.std():.2f}$ [{np.percentile(ec_mix_reward, 5):.2f}] \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5.2 - Grid Reliance\n",
    "\n",
    "# DA\n",
    "ec_qnt = sum([np.where(np.array(da_info[aid][\"qnt\"])>=0, np.array(da_info[aid][\"qnt\"]), 0) for aid in agents]).sum(axis=-1)\n",
    "ec_grid_qnt = sum([np.where(np.array(da_info[aid][\"da_grid_qnt\"])>=0, np.array(da_info[aid][\"da_grid_qnt\"]), 0) for aid in agents]).sum(axis=-1)\n",
    "grid_reliance = ec_grid_qnt/ec_qnt\n",
    "print(f\"DA & ${grid_reliance.mean():.2f} \\\\pm {grid_reliance.std():.2f}$ [{np.percentile(grid_reliance, 95):.2f}] \\\\\\\\\")\n",
    "\n",
    "# Pool\n",
    "ec_pool_qnt = sum([np.array(pool_info[aid][\"qnt\"]) for aid in agents])\n",
    "ec_pool_qnt = np.where(ec_pool_qnt>=0, ec_pool_qnt, 0).sum(axis=-1)\n",
    "ec_qnt = sum([np.where(np.array(pool_info[aid][\"qnt\"])>=0, np.array(pool_info[aid][\"qnt\"]), 0) for aid in agents]).sum(axis=-1)\n",
    "grid_reliance = ec_pool_qnt/ec_qnt\n",
    "print(f\"Pool & ${grid_reliance.mean():.2f} \\\\pm {grid_reliance.std():.2f}$ [{np.percentile(grid_reliance, 95):.2f}] \\\\\\\\\")\n",
    "\n",
    "# Mix\n",
    "ec_grid_qnt = sum([np.where(np.array(mix_info[aid][\"da_grid_qnt\"])>=0, np.array(mix_info[aid][\"da_grid_qnt\"]), 0) for aid in agents]).sum(axis=-1)\n",
    "ec_pool_qnt = sum([np.array(mix_info[aid][\"mix_pool_qnt\"]) for aid in agents])\n",
    "ec_pool_qnt = np.where(ec_pool_qnt>=0, ec_pool_qnt, 0).sum(axis=-1)\n",
    "ec_total_grid = ec_grid_qnt + ec_pool_qnt\n",
    "ec_qnt = sum([np.where(np.array(mix_info[aid][\"qnt\"])>=0, np.array(mix_info[aid][\"qnt\"]), 0) for aid in agents]).sum(axis=-1)\n",
    "grid_reliance = ec_total_grid/ec_qnt\n",
    "print(f\"Mix & ${grid_reliance.mean():.2f} \\\\pm {grid_reliance.std():.2f}$ [{np.percentile(grid_reliance, 95):.2f}] \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c9239",
   "metadata": {},
   "source": [
    "### Chapter 6: ES Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec94281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean masks for seasonalities\n",
    "summer_bool = np.array(is_summer_list)[test_days]\n",
    "winter_bool = np.array(is_winter_list)[test_days]\n",
    "weekend_bool = np.array(is_weekend_list)[test_days]\n",
    "\n",
    "weekend_filter = weekend_bool | (~ (summer_bool | winter_bool))\n",
    "summer_filter = summer_bool & (~weekend_bool)\n",
    "winter_filter = winter_bool & (~weekend_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_power(data_dict, agents, color_mapping, save_path=None):\n",
    "    \"\"\"\n",
    "    Stacked bar chart with positive and negative values separated.\n",
    "    \"\"\"\n",
    "    hours = np.arange(24)\n",
    "    plt.figure()\n",
    "\n",
    "    # Initialize running totals\n",
    "    pos_bottom = np.zeros(24)\n",
    "    neg_bottom = np.zeros(24)\n",
    "\n",
    "    for agent in agents:\n",
    "        values = np.squeeze(data_dict[agent])\n",
    "        \n",
    "        # Split into positive and negative parts\n",
    "        pos_vals = np.where(values > 0, values, 0)\n",
    "        neg_vals = np.where(values < 0, values, 0)\n",
    "        \n",
    "        # Plot positives (stacked upwards)\n",
    "        plt.bar(hours, pos_vals, bottom=pos_bottom,\n",
    "                color=color_mapping.get(agent, None),\n",
    "                label=agent, width=0.75)\n",
    "        pos_bottom += pos_vals\n",
    "        \n",
    "        # Plot negatives (stacked downwards)\n",
    "        plt.bar(hours, neg_vals, bottom=neg_bottom,\n",
    "                color=color_mapping.get(agent, None),\n",
    "                width=0.75)\n",
    "        neg_bottom += neg_vals\n",
    "\n",
    "    # Formatting\n",
    "    plt.xticks(hours)\n",
    "    plt.xlabel(\"Hour of Day ($t$)\")\n",
    "    plt.ylabel(\"Charge or Discharge (kWh)\", labelpad=8)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(ncol=2, fontsize=16, frameon=True, loc='lower left', bbox_to_anchor=(0.025, 0.06))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.ylim(ymin * 1.05, ymax * 1.05)   # add 5% space\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 6.1 and 6.2\n",
    "mean_es_charge = {aid: np.array(mix_info[aid]['es_charge'])[:,weekend_filter,:].mean(axis=(0,1)) for aid in agents}\n",
    "plot_stacked_power(mean_es_charge, sorted(agents), color_mapping, save_path=\"thesis_results/plots/06_discussion/mix_es_charge_weekend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84969568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_soc_actions(data_dict, agents, color_mapping, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot SoC actions for each agent as line plots over 24 hours.\n",
    "\n",
    "    Args:\n",
    "        data_dict: dict {agent: np.array of shape (24,) or (24,1)}\n",
    "        agents: list of agent names to plot\n",
    "        color_mapping: dict {agent: color string}\n",
    "        legend_loc: legend location code (default=0 = best)\n",
    "        save_path: optional path to save figure\n",
    "    \"\"\"\n",
    "    hours = np.arange(24)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for agent in agents:\n",
    "        values = np.squeeze(data_dict[agent])  # shape (24,)\n",
    "        color = color_mapping.get(agent, None)\n",
    "        plt.plot(hours, values, label=agent, color=color, linewidth=2.4)\n",
    "\n",
    "    # Formatting\n",
    "    plt.xticks(hours, [f\"{h}\" for h in hours])  # 0–23 labels\n",
    "    plt.xlabel(\"Hour of Day ($t$)\")\n",
    "    plt.ylabel(\"SoC Action\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(fontsize=17) # 15.5 for appendix\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 6.3\n",
    "mean_soc_action = {aid: np.array(mix_info[aid]['soc_action']).mean(axis=(0,1)) for aid in agents}\n",
    "plot_soc_actions(mean_soc_action, sorted(agents), color_mapping, save_path=\"thesis_results/plots/06_discussion/mix_soc_actions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hack for Appendix B ###\n",
    "\n",
    "# Dummy for task config\n",
    "exp_path = f\"results/da/maddpg/seed_0/checkpoints/checkpoint_434176.pt\" # only seed and run\n",
    "exp = Experiment.reload_from_file(exp_path)\n",
    "config = exp.task.config\n",
    "\n",
    "# Single env for all evaluations\n",
    "trading_env = EnergyTradingEnv(config, render_mode=None)\n",
    "trading_env.reset(seed=2025)\n",
    "\n",
    "maddpg_info = get_results(exp, trading_env, 0, 'damaddpg', use_contracts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots for Appendix B ###\n",
    "\n",
    "# mean_es_charge = {aid: np.array(maddpg_info[aid]['es_charge']).mean(axis=0) for aid in agents}\n",
    "# plot_stacked_power(mean_es_charge, sorted(agents), color_mapping, save_path=\"thesis_results/plots/appendix_B/maddpg_es_charge.png\")\n",
    "\n",
    "mean_soc_action = {aid: np.array(maddpg_info[aid]['soc_action']).mean(axis=0) for aid in agents}\n",
    "plot_soc_actions(mean_soc_action, sorted(agents), color_mapping, save_path=\"thesis_results/plots/appendix_B/maddpg_soc_actions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70aef1",
   "metadata": {},
   "source": [
    "### Chapter 6: P2P Volume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_p2p_qnt = sum([np.where(np.array(da_info[aid][\"da_p2p_qnt\"])>=0, np.array(da_info[aid][\"da_p2p_qnt\"]), 0) for aid in agents])\n",
    "p2p_da = da_p2p_qnt.mean(axis=(0,1))\n",
    "\n",
    "ec_qnt_pos = sum([np.where(np.array(pool_info[aid][\"qnt\"])>=0, np.array(pool_info[aid][\"qnt\"]), 0) for aid in agents])\n",
    "ec_qnt_neg = sum([np.where(np.array(pool_info[aid][\"qnt\"])<0, -np.array(pool_info[aid][\"qnt\"]), 0) for aid in agents])\n",
    "p2p_pool = np.minimum(ec_qnt_pos, ec_qnt_neg).mean(axis=(0,1))\n",
    "\n",
    "ec_qnt_pos = sum([np.where(np.array(mix_info[aid][\"mix_pool_qnt\"])>=0, np.array(mix_info[aid][\"mix_pool_qnt\"]), 0) for aid in agents])\n",
    "ec_qnt_neg = sum([np.where(np.array(mix_info[aid][\"mix_pool_qnt\"])<0, -np.array(mix_info[aid][\"mix_pool_qnt\"]), 0) for aid in agents])\n",
    "da_p2p_qnt = sum([np.where(np.array(mix_info[aid][\"da_p2p_qnt\"])>=0, np.array(mix_info[aid][\"da_p2p_qnt\"]), 0) for aid in agents])\n",
    "p2p_mix = (np.minimum(ec_qnt_pos, ec_qnt_neg) + da_p2p_qnt).mean(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as a bar plot, Figure 6.4\n",
    "hours = np.arange(24)  # 24 hours in a day\n",
    "\n",
    "plt.bar(hours-0.22, p2p_da, color='skyblue', edgecolor='grey', width=0.22, label='DA', align='center')\n",
    "plt.bar(hours, p2p_pool, color='salmon', edgecolor='grey', width=0.22, label='Pool', align='center')\n",
    "plt.bar(hours+0.22, p2p_mix, color='lightgreen', edgecolor='grey', width=0.22, label='Mix', align='center')\n",
    "plt.legend()\n",
    "\n",
    "# Formatting\n",
    "plt.xticks(hours, [f\"{h}\" for h in hours])  # 0–23 labels\n",
    "plt.xlabel(\"Hour of Day ($t$)\")\n",
    "plt.ylabel(\"P2P Volume (kWh)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ba7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that there's early sell off on weekends\n",
    "sell_off = np.array(base_info[\"prosumer_1\"][\"qnt\"])[:,weekend_filter,:].mean(axis=(0,1))\n",
    "print(sell_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67067182",
   "metadata": {},
   "source": [
    "### Chapter 6: DA Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if pricing causes unmatched trades in DA\n",
    "da_unmatched = np.array(mix_info[\"prosumer_1\"][\"da_unmatched\"]).flatten()\n",
    "unique, counts = np.unique(da_unmatched, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 6.6, Average Matching Price\n",
    "mean_da_price = np.array(da_info[\"prosumer_1\"]['avg_clearing_price'])\n",
    "mean_da_price = np.where(mean_da_price==-1, np.nan, mean_da_price)\n",
    "mean_da_price = np.nanmean(mean_da_price, axis=(0,1))\n",
    "\n",
    "mean_mix_price = np.array(mix_info[\"prosumer_1\"]['avg_clearing_price'])\n",
    "mean_mix_price = np.where(mean_mix_price==-1, np.nan, mean_mix_price)\n",
    "mean_mix_price = np.nanmean(mean_mix_price, axis=(0,1))\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "hours = np.arange(24)\n",
    "plt.plot(hours, mean_da_price, label=\"DA\", linewidth=2)\n",
    "plt.plot(hours, mean_mix_price, label=\"Mix\", linewidth=2)\n",
    "\n",
    "# Formatting\n",
    "plt.xticks(hours, [f\"{h}\" for h in hours])  # 0–23 labels\n",
    "plt.xlabel(\"Hour of Day ($t$)\")\n",
    "plt.ylabel(\"DA Matching Price\")\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "plt.legend(frameon=True, loc='lower left', bbox_to_anchor=(0.05, 0.05))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"thesis_results/plots/06_discussion/da_price_match.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 6.5, Price Actions\n",
    "def plot_price_actions(data_dict, agents, color_mapping, save_path=None):\n",
    "    \n",
    "    hours = np.arange(24)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for agent in agents:\n",
    "        values = np.squeeze(data_dict[agent])  # shape (24,)\n",
    "        color = color_mapping.get(agent, None)\n",
    "        plt.plot(hours, values, label=agent, color=color, linewidth=2.4)\n",
    "\n",
    "    # Formatting\n",
    "    plt.xticks(hours, [f\"{h}\" for h in hours])  # 0–23 labels\n",
    "    plt.xlabel(\"Hour of Day ($t$)\")\n",
    "    plt.ylabel(\"Price Action\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(ncol=2, fontsize=15, frameon=True, loc='lower left', bbox_to_anchor=(0.01, 0.03))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15146aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price_action = {aid: np.array(mix_info[aid]['price_action']).mean(axis=(0,1)) for aid in agents}\n",
    "plot_price_actions(mean_price_action, sorted(agents), color_mapping, save_path=\"thesis_results/plots/06_discussion/mix_price_actions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA Grid Reliance, Table 6.1\n",
    "\n",
    "for aid in sorted(agents):\n",
    "    \n",
    "    qnt = np.where(np.array(da_info[aid][\"qnt\"])>=0, np.array(da_info[aid][\"qnt\"]), 0).sum(axis=-1)\n",
    "    grid_qnt = np.where(np.array(da_info[aid][\"da_grid_qnt\"])>=0, np.array(da_info[aid][\"da_grid_qnt\"]), 0).sum(axis=-1)\n",
    "    grid_reliance = np.divide(grid_qnt, qnt, out=np.zeros_like(grid_qnt, dtype=float), where=qnt!=0)\n",
    "    print(f\"{aid} & ${grid_reliance.mean():.2f} \\\\pm {grid_reliance.std():.2f}$ [{np.percentile(grid_reliance, 95):.2f}] \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d0036",
   "metadata": {},
   "source": [
    "### Chapter 6: Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 6.2\n",
    "relative_savings = {'da':[], 'pool':[], 'mix':[]}\n",
    "\n",
    "for aid in sorted(agents):\n",
    "\n",
    "    base_reward = np.array(base_info[aid][\"reward\"]).sum(axis=-1)\n",
    "    da_reward = np.array(da_info[aid][\"reward\"]).sum(axis=-1)\n",
    "    pool_reward = np.array(pool_info[aid][\"reward\"]).sum(axis=-1)\n",
    "    mix_reward = np.array(mix_info[aid][\"reward\"]).sum(axis=-1)\n",
    "\n",
    "    da_savings = da_reward - base_reward\n",
    "    pool_savings = pool_reward - base_reward\n",
    "    mix_savings = mix_reward - base_reward\n",
    "\n",
    "    relative_savings['da'].append(da_savings.flatten())\n",
    "    relative_savings['pool'].append(pool_savings.flatten())\n",
    "    relative_savings['mix'].append(mix_savings.flatten())\n",
    "\n",
    "    print(f\"{aid} & ${da_savings.mean():.2f} \\\\pm {da_savings.std():.2f}$ [{np.percentile(da_savings, 5):.2f}] & ${pool_savings.mean():.2f} \\\\pm {pool_savings.std():.2f}$ [{np.percentile(pool_savings, 5):.2f}] & ${mix_savings.mean():.2f} \\\\pm {mix_savings.std():.2f}$ [{np.percentile(mix_savings, 5):.2f}] \\\\\\\\\")\n",
    "\n",
    "ec_base_reward = sum([np.array(base_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1)\n",
    "ec_da_savings = sum([np.array(da_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1) - ec_base_reward\n",
    "ec_pool_savings = sum([np.array(pool_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1) - ec_base_reward\n",
    "ec_mix_savings = sum([np.array(mix_info[aid][\"reward\"]) for aid in agents]).sum(axis=-1) - ec_base_reward\n",
    "\n",
    "print(f\"Community & ${ec_da_savings.mean():.2f} \\\\pm {ec_da_savings.std():.2f}$ [{np.percentile(ec_da_savings, 5):.2f}] & ${ec_pool_savings.mean():.2f} \\\\pm {ec_pool_savings.std():.2f}$ [{np.percentile(ec_pool_savings, 5):.2f}] & ${ec_mix_savings.mean():.2f} \\\\pm {ec_mix_savings.std():.2f}$ [{np.percentile(ec_mix_savings, 5):.2f}] \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176afd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_per_scenario(x):\n",
    "    \"\"\"\n",
    "    Compute Gini coefficient for each scenario/day.\n",
    "    Args:\n",
    "        x: np.ndarray of shape (8, N)  # 8 agents × N scenarios\n",
    "    Returns:\n",
    "        np.ndarray of shape (N,) with Gini per scenario\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    n_scenarios = x.shape[1]\n",
    "    gini_vals = np.zeros(n_scenarios)\n",
    "\n",
    "    for i in range(n_scenarios):\n",
    "        vals = np.sort(x[:, i])\n",
    "\n",
    "        # # Shift to non-negative\n",
    "        # # Doesn't work so well, Ignore negatives for now\n",
    "        # if vals[0]<0:\n",
    "        #     vals = vals - vals[0] + 1e-8\n",
    "\n",
    "        if np.all(vals == 0):\n",
    "            gini_vals[i] = 0.0\n",
    "            continue\n",
    "        n = len(vals)\n",
    "        index = np.arange(1, n + 1)\n",
    "        gini_vals[i] = (2 * np.sum(index * vals) / (n * np.sum(vals))) - (n + 1) / n\n",
    "\n",
    "    return gini_vals\n",
    "\n",
    "for key in relative_savings:\n",
    "    relative_savings[key] = np.array(relative_savings[key])\n",
    "\n",
    "## Check negatives\n",
    "# negative_counts = {key: np.sum(relative_savings[key] < 0, axis=1) for key in relative_savings}\n",
    "# print(negative_counts)\n",
    "\n",
    "# Remove negative cases for Gini\n",
    "for key in relative_savings:\n",
    "    relative_savings[key] = relative_savings[key][:, ~np.any(relative_savings[key] < 0, axis=0)]\n",
    "\n",
    "gini = {key: gini_per_scenario(relative_savings[key]) for key in relative_savings}\n",
    "\n",
    "# Table 6.3\n",
    "for key in gini:\n",
    "    print(f\"{key} & ${gini[key].mean():.3f} \\\\pm {gini[key].std():.3f}$ [{np.percentile(gini[key], 95):.3f}] \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fb9ab",
   "metadata": {},
   "source": [
    "### Chapter 6: Optimal Contracts Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ff4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contracts(data_dict, agents, color_mapping, save_path=None):\n",
    "    \n",
    "    hours = np.arange(24)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for agent in agents:\n",
    "        values = np.squeeze(data_dict[agent])  # shape (24,)\n",
    "        color = color_mapping.get(agent, None)\n",
    "        plt.plot(hours, values, label=agent, color=color, linewidth=2.4)\n",
    "\n",
    "    # Formatting\n",
    "    plt.xticks(hours, [f\"{h}\" for h in hours])  # 0–23 labels\n",
    "    plt.xlabel(\"Hour of Day ($t$)\")\n",
    "    plt.ylabel(\"Contract (Pool Share)\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(ncol=2, fontsize=15.5, frameon=True, loc='lower right', bbox_to_anchor=(0.955, 0.01))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.ylim(ymin * 0.95, ymax * 1)   # add 5% space\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed name to avoid conflict\n",
    "opt_contract = {aid: [] for aid in agents}\n",
    "\n",
    "for seed in stage_2_seeds:\n",
    "\n",
    "    for is_summer, is_winter, is_weekend in [(False, False, False), # Other\n",
    "                                             (False, False, True), # Other\n",
    "                                             (False, True, True), # Other\n",
    "                                             (True, False, True), # Other\n",
    "                                             (True, False, False), # Summer\n",
    "                                             (False, True, False)]: # Winter\n",
    "\n",
    "        contract = optimal_contracts[(seed, is_weekend, is_summer, is_winter)]\n",
    "\n",
    "        for aid in agents:\n",
    "            opt_contract[aid].append([contract[t][aid] for t in range(24)])\n",
    "\n",
    "for aid in agents:\n",
    "    opt_contract[aid] = np.array(opt_contract[aid]).mean(axis=0)\n",
    "\n",
    "# Plot 6.7\n",
    "plot_contracts(opt_contract, sorted(agents), color_mapping, save_path=\"thesis_results/plots/06_discussion/optimal_contracts.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchrl_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
