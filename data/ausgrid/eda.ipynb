{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ffd465",
   "metadata": {},
   "source": [
    "Process the raw Ausgrid solar data to a more usable format.<br>\n",
    "Inspired by: https://github.com/pierre-haessig/ausgrid-solar-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a05245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined 3 years:\n",
    "# 2010-2011 Solar home electricity data.csv\n",
    "# 2011-2012 Solar home electricity data v2.csv\n",
    "# 2012-2013 Solar home electricity data v2.csv\n",
    "fname = 'solar.csv'\n",
    "\n",
    "d_raw = pd.read_csv(fname, skiprows=1,\n",
    "                    parse_dates=['date'], dayfirst=True,\n",
    "                    na_filter=False, dtype={'Row Quality': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to indicate if the date is a weekend\n",
    "d_raw['Weekend'] = d_raw['date'].dt.dayofweek >= 5\n",
    "\n",
    "# Add a column to indicate if the date is in Summer (November to March)\n",
    "d_raw['Summer'] = d_raw['date'].dt.month.isin([11, 12, 1, 2, 3])\n",
    "\n",
    "# Add a column to indicate if the date is in Winter (June to August)\n",
    "d_raw['Winter'] = d_raw['date'].dt.month.isin([6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18c542",
   "metadata": {},
   "source": [
    "#### Pick suitable customers for the Environment (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94aacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by postcode for some consistency\n",
    "postcode_counts = d_raw['Postcode'].value_counts()\n",
    "print(\"Top 5 postcodes with most samples:\")\n",
    "print(postcode_counts.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get customers in a specific postcode\n",
    "postcode = 2262\n",
    "\n",
    "d_post = d_raw[d_raw['Postcode'] == postcode].copy()\n",
    "d_post_cust = d_post['Customer'].unique().tolist()\n",
    "print(f\"Customers in postcode {postcode}: {len(d_post_cust)}\")\n",
    "print(d_post_cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac27867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some statistics\n",
    "for id in d_post_cust:\n",
    "    \n",
    "    d_customer = d_raw[d_raw['Customer'] == id]\n",
    "\n",
    "    d_pv = d_customer[d_customer['Consumption Category'] == 'GG'].to_numpy()[:,5:53].flatten()\n",
    "    d_d = d_customer[d_customer['Consumption Category'] == 'GC'].to_numpy()[:,5:53].flatten()\n",
    "\n",
    "    print(f\"Customer {id}\")\n",
    "    print(f\"Generator Capacity: {d_customer['Generator Capacity'].iloc[0]} kWp\")\n",
    "    print(f\"Average Generation: {d_pv.mean():.2f} kWh\")\n",
    "    print(f\"Average Consumption: {d_d.mean():.2f} kWh\")\n",
    "    # print(d_d.shape, d_pv.shape)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get big players, in search of liquidity\n",
    "top_customers = d_raw.sort_values(\"Generator Capacity\", ascending=False)[\"Customer\"].unique()[:10]\n",
    "top_capacities = [d_raw[d_raw[\"Customer\"] == cid][\"Generator Capacity\"].iloc[0] for cid in top_customers]\n",
    "print(\"Top 10 customers with highest generator capacity:\")\n",
    "for cid, cap in zip(top_customers, top_capacities):\n",
    "    print(f\"Customer {cid}: {cap} kWp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot net demand for a specific customer\n",
    "# Should aim to get prosumers that provide good liquidity?\n",
    "id = 119\n",
    "is_prosumer = False\n",
    "\n",
    "d_customer = d_raw[d_raw['Customer'] == id]\n",
    "\n",
    "# Change filters as needed\n",
    "d_pv = d_customer[(d_customer['Consumption Category'] == 'GG') & \n",
    "                  (d_customer['Summer']) & \n",
    "                  (~d_customer['Weekend'])].to_numpy()[:, 5:53]\n",
    "d_pv_hourly = d_pv.reshape(d_pv.shape[0], 24, 2).sum(axis=2)\n",
    "\n",
    "# Change filters as needed\n",
    "d_d = d_customer[(d_customer['Consumption Category'] == 'GC') & \n",
    "                 (d_customer['Summer']) & \n",
    "                 (~d_customer['Weekend'])].to_numpy()[:, 5:53]\n",
    "d_d_hourly = d_d.reshape(d_d.shape[0], 24, 2).sum(axis=2)\n",
    "\n",
    "d_load = d_d_hourly - d_pv_hourly if is_prosumer else d_d_hourly\n",
    "\n",
    "d_load_mean = d_load.astype(np.float32).mean(axis=0)\n",
    "d_load_std = np.std(d_load.astype(np.float32), axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(24), d_load_mean, marker='o', label='Mean Net Demand')\n",
    "plt.fill_between(range(24), d_load_mean - d_load_std, d_load_mean + d_load_std, color='gray', alpha=0.3, label='±1 Std Dev')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Net Demand (kWh)')\n",
    "plt.title(f'Customer {id} (as {\"Prosumer\" if is_prosumer else \"Consumer\"})')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(24))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0dfd5",
   "metadata": {},
   "source": [
    "#### Pick agents from the \"Clean Dataset\"\n",
    "Taken from Residential load and rooftop PV generation: an Australian distribution network dataset (https://doi.org/10.1080/14786451.2015.1100196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_agents = [2, 13, 14, 20, 33, 35, 38, 39, 56,\n",
    "                69, 73, 74, 75, 82, 87, 88, 101, 104,\n",
    "                106, 109, 110, 119, 124, 130, 137, 141, 144,\n",
    "                152, 153, 157, 161, 169, 176, 184, 188, 189,\n",
    "                193, 201, 202, 204, 206, 207, 210, 211, 212,\n",
    "                214, 218, 244, 246, 253, 256, 273, 276, 297]\n",
    "\n",
    "clean_agents.remove(2) # Some missing data\n",
    "clean_agents.remove(161) # Anamolous CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324bb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results/consumer', exist_ok=True)\n",
    "os.makedirs('results/prosumer', exist_ok=True)\n",
    "\n",
    "# Plot net demand for all agents (both as consumer and prosumer) and save as PNGs\n",
    "for id in tqdm(clean_agents, desc=\"Processing clean agents\"):\n",
    "\n",
    "    d_customer = d_raw[d_raw['Customer'] == id]\n",
    "\n",
    "    # Change filters as needed\n",
    "    d_pv = d_customer[(d_customer['Consumption Category'] == 'GG') & \n",
    "                  (d_customer['Winter']) & \n",
    "                  (~d_customer['Weekend'])].to_numpy()[:, 5:53]\n",
    "\n",
    "    d_pv_hourly = d_pv.reshape(d_pv.shape[0], 24, 2).sum(axis=2)\n",
    "\n",
    "    # Change filters as needed\n",
    "    d_d = d_customer[(d_customer['Consumption Category'] == 'GC') & \n",
    "                 (d_customer['Winter']) & \n",
    "                 (~d_customer['Weekend'])].to_numpy()[:, 5:53]\n",
    "    \n",
    "    d_d_hourly = d_d.reshape(d_d.shape[0], 24, 2).sum(axis=2)\n",
    "\n",
    "    for is_prosumer in [False, True]:\n",
    "\n",
    "        d_load = d_d_hourly - d_pv_hourly if is_prosumer else d_d_hourly\n",
    "\n",
    "        d_load_mean = d_load.astype(np.float32).mean(axis=0)\n",
    "        d_load_std = d_load.astype(np.float32).std(axis=0)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(24), d_load_mean, marker='o', label='Mean Net Demand')\n",
    "        plt.fill_between(range(24), d_load_mean - d_load_std, d_load_mean + d_load_std, color='gray', alpha=0.3, label='±1 Std Dev')\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Net Demand (kWh)')\n",
    "        plt.title(f'Customer {id} (as {\"Prosumer\" if is_prosumer else \"Consumer\"})')\n",
    "        plt.grid(True)\n",
    "        plt.xticks(range(24))\n",
    "        plt.legend()\n",
    "        plt.savefig(f'results/{'prosumer' if is_prosumer else 'consumer'}/customer_{id}_net_demand.png')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3d104",
   "metadata": {},
   "source": [
    "#### Save processed data to a json file (for MARL environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumers = [69, 184, 189, 212]\n",
    "prosumers = [110, 119, 193, 256]\n",
    "\n",
    "json_data = dict()\n",
    "\n",
    "d_sample = d_raw[(d_raw['Customer'] == prosumers[0]) &\n",
    "                 (d_raw['Consumption Category'] == 'GC')]\n",
    "\n",
    "d_sample = d_sample.reset_index(drop=True)\n",
    "\n",
    "d_weekend = d_sample['Weekend'].to_list()\n",
    "d_summer = d_sample['Summer'].to_list()\n",
    "d_winter = d_sample['Winter'].to_list()\n",
    "\n",
    "start_date = d_sample['date'].min().strftime('%d-%m-%Y')\n",
    "end_date = d_sample['date'].max().strftime('%d-%m-%Y')\n",
    "\n",
    "# Randomly pick one day from each week as test day\n",
    "np.random.seed(5)  # For reproducibility\n",
    "unique_weeks = d_sample['date'].dt.to_period('W').unique()\n",
    "test_days = [int(d_sample[d_sample['date'].dt.to_period('W') == week].sample(1).index[0]) for week in unique_weeks]\n",
    "train_days = [i for i in range(len(d_sample)) if i not in test_days]\n",
    "\n",
    "json_data['meta'] = {'start_date': start_date,\n",
    "                     'end_date': end_date,\n",
    "                     'is_weekend': d_weekend,\n",
    "                     'is_summer': d_summer,\n",
    "                     'is_winter': d_winter,\n",
    "                     'train_days': train_days,\n",
    "                     'test_days': test_days}\n",
    "\n",
    "for id in sorted(consumers + prosumers):\n",
    "    \n",
    "    d_customer = d_raw[d_raw['Customer'] == id]\n",
    "\n",
    "    d_pv = d_customer[d_customer['Consumption Category'] == 'GG'].to_numpy()[:,5:53].flatten()\n",
    "    d_d = d_customer[d_customer['Consumption Category'] == 'GC'].to_numpy()[:,5:53].flatten()\n",
    "\n",
    "    # Aggregate half-hourly data to hourly by summing consecutive pairs\n",
    "    d_pv = d_pv.reshape(-1, 2).sum(axis=1)\n",
    "    d_d = d_d.reshape(-1, 2).sum(axis=1)\n",
    "\n",
    "    json_data[id] = {'prosumer': True if id in prosumers else False,\n",
    "                     'pv_capacity': d_customer['Generator Capacity'].iloc[0],\n",
    "                     'pv': d_pv.tolist(),\n",
    "                     'demand': d_d.tolist()} \n",
    "\n",
    "for id in sorted(consumers + prosumers):\n",
    "\n",
    "    pv = json_data[id]['pv']\n",
    "    demand = json_data[id]['demand']\n",
    "\n",
    "    pv_scaler = MinMaxScaler()\n",
    "    demand_scaler = MinMaxScaler()\n",
    "\n",
    "    pv_scaled = pv_scaler.fit_transform(np.array(pv).reshape(-1, 1)).flatten().tolist()\n",
    "    demand_scaled = demand_scaler.fit_transform(np.array(demand).reshape(-1, 1)).flatten().tolist()\n",
    "\n",
    "    json_data[id]['pv_scaled'] = pv_scaled\n",
    "    json_data[id]['demand_scaled'] = demand_scaled\n",
    "    json_data[id]['pv_max'] = pv_scaler.data_max_[0]\n",
    "    json_data[id]['demand_max'] = demand_scaler.data_max_[0]\n",
    "\n",
    "# Save to JSON file\n",
    "with open('group_4.json', 'w') as f:\n",
    "    json.dump(json_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6466ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of test days across weekdays (seed=5 and 42 are sweet)\n",
    "weekdays = d_sample['date'].dt.dayofweek.to_list()\n",
    "\n",
    "test_weekdays = [weekdays[day] for day in test_days]\n",
    "day_distribution = Counter(test_weekdays)\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "for i, count in sorted(day_distribution.items()):\n",
    "    print(f\"{day_names[i]}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchrl_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
